{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3xukQ0V2noj"
   },
   "source": [
    "Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "yyEssouwiP9M",
    "outputId": "df3724ff-c23e-469b-ff8c-e844bc1b4031"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gNGboUdX2F2Z"
   },
   "outputs": [],
   "source": [
    "classN_img_path = \"Data/train/normal\"\n",
    "classA_img_path = \"Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\"\n",
    "classL_img_path = \"Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\"\n",
    "classS_img_path = \"Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\"\n",
    "\n",
    "image_paths = {\"normal\": classN_img_path, \n",
    "               \"adenocarcinoma\": classA_img_path,\n",
    "               \"large_cell_carcinoma\": classL_img_path, \n",
    "               \"squamous_cell_carcinoma\": classS_img_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(folder_path, target_size):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            img = Image.open(os.path.join(folder_path, filename))\n",
    "            img = img.resize(target_size, Image.LANCZOS)\n",
    "            base_filename, file_extension = os.path.splitext(filename)\n",
    "            img.save(os.path.join(folder_path, f'{base_filename}_resized{file_extension}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images(image_files):\n",
    "    orb = cv2.ORB_create()\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    reference_image_path = random.choice(image_files)\n",
    "    img1 = cv2.imread(reference_image_path, 0)\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "\n",
    "    for image_path in image_files:\n",
    "        if image_path != reference_image_path:\n",
    "            img2 = cv2.imread(image_path, 0)\n",
    "\n",
    "            kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "            matches = bf.match(des1, des2)\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "            points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "            points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "            for i, match in enumerate(matches):\n",
    "                points1[i, :] = kp1[match.queryIdx].pt\n",
    "                points2[i, :] = kp2[match.trainIdx].pt\n",
    "\n",
    "            h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "            img2_aligned = cv2.warpPerspective(img2, h, (img1.shape[1], img1.shape[0]))\n",
    "\n",
    "            aligned_image_path = os.path.splitext(image_path)[0] + '_aligned' + os.path.splitext(image_path)[1]\n",
    "            cv2.imwrite(aligned_image_path, img2_aligned)\n",
    "\n",
    "def align_resized_images(folder_path):\n",
    "    # Get all image files in the folder\n",
    "    image_files = glob.glob(os.path.join(folder_path, '*resized*'))\n",
    "    \n",
    "\n",
    "    # Align images\n",
    "    align_images(image_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_image(image_files):\n",
    "    img_sum = None\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        img = cv2.imread(image_file).astype(np.float32)\n",
    "        if img_sum is None:\n",
    "            img_sum = img\n",
    "        else:\n",
    "            img_sum += img\n",
    "\n",
    "    mean_img = img_sum / len(image_files)\n",
    "    mean_img = mean_img.astype(np.uint8)\n",
    "\n",
    "    return mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_mean_image(image_files, mean_img):\n",
    "    orb = cv2.ORB_create()\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    kp1, des1 = orb.detectAndCompute(mean_img, None)\n",
    "\n",
    "    for image_path in image_files:\n",
    "        if not '_aligned' in image_path and '_resized' in image_path:\n",
    "            img2 = cv2.imread(image_path, 0)\n",
    "\n",
    "            kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "            matches = bf.match(des1, des2)\n",
    "\n",
    "            # Ensure there are enough matches\n",
    "            if len(matches) < 4:\n",
    "                print(f\"Not enough matches found in {image_path}\")\n",
    "                continue\n",
    "\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "            points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "            points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "            for i, match in enumerate(matches):\n",
    "                points1[i, :] = kp1[match.queryIdx].pt\n",
    "                points2[i, :] = kp2[match.trainIdx].pt\n",
    "\n",
    "            h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "            \n",
    "            if h is None:\n",
    "                print(f\"Could not find a valid homography for image {image_path}.\")\n",
    "                continue\n",
    "\n",
    "            img2_aligned = cv2.warpPerspective(img2, h, (mean_img.shape[1], mean_img.shape[0]))\n",
    "\n",
    "            # Overwrite the aligned image if it exists\n",
    "            aligned_image_path = image_path.rsplit('_', 1)[0] + '_aligned' + os.path.splitext(image_path)[1]\n",
    "            cv2.imwrite(aligned_image_path, img2_aligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, max_iterations=10, convergence_threshold=1e-6):\n",
    "    # Get all image files in the folder\n",
    "    image_files = glob.glob(os.path.join(folder_path, '*resized*'))\n",
    "\n",
    "    # Compute initial mean image\n",
    "    mean_img = compute_mean_image(image_files)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Align images to current mean image\n",
    "        align_to_mean_image(image_files, mean_img)\n",
    "\n",
    "        # Compute new mean image\n",
    "        new_mean_img = compute_mean_image([f.rsplit('_', 1)[0] + '_aligned' + os.path.splitext(f)[1] for f in image_files])\n",
    "\n",
    "        # Compute the difference between the new and old mean image\n",
    "        diff = np.mean(np.abs(new_mean_img - mean_img))\n",
    "\n",
    "        # Update the mean image\n",
    "        mean_img = new_mean_img\n",
    "\n",
    "        # If the difference is below the convergence threshold, stop iterating\n",
    "        if diff < convergence_threshold:\n",
    "            break\n",
    "\n",
    "    # Save the final mean image\n",
    "    cv2.imwrite(os.path.join(folder_path, 'mean_image.jpg'), mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_altered_images(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if 'resized' in filename or 'aligned' in filename or 'mean_image' in filename:\n",
    "            os.remove(os.path.join(folder_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@94907.229] global loadsave.cpp:248 findDecoder imread_('Data/train/normal/5 - Copy - Copy_aligned_aligned.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m resize_images(image_path, (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m      4\u001b[0m align_resized_images(image_path)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[72], line 13\u001b[0m, in \u001b[0;36mprocess_folder\u001b[0;34m(folder_path, max_iterations, convergence_threshold)\u001b[0m\n\u001b[1;32m     10\u001b[0m align_to_mean_image(image_files, mean_img)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Compute new mean image\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m new_mean_img \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mean_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_aligned\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute the difference between the new and old mean image\u001b[39;00m\n\u001b[1;32m     16\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(new_mean_img \u001b[38;5;241m-\u001b[39m mean_img))\n",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m, in \u001b[0;36mcompute_mean_image\u001b[0;34m(image_files)\u001b[0m\n\u001b[1;32m      2\u001b[0m img_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[0;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img_sum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         img_sum \u001b[38;5;241m=\u001b[39m img\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "for label, image_path in image_paths.items():\n",
    "    remove_resized_images(image_path)\n",
    "    resize_images(image_path, (256, 256))\n",
    "    align_resized_images(image_path)\n",
    "    process_folder(image_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_images(folder_path, rmse_threshold=7.0, target_size=(256, 256)):\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "    deduplicated_images = []\n",
    "\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        image1_path = os.path.join(folder_path, image_file)\n",
    "        image1 = Image.open(image1_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        image1 = image1.convert('L')\n",
    "\n",
    "        # Resize the image to the target size\n",
    "        image1 = resize_image(image1, target_size)\n",
    "\n",
    "        is_duplicate = False\n",
    "        for dedup_image in deduplicated_images:\n",
    "            image2 = dedup_image[0]\n",
    "            rmse = compute_rmse(image1, image2)\n",
    "            if rmse < rmse_threshold:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "\n",
    "        if not is_duplicate:\n",
    "            deduplicated_images.append((image1, image_file))\n",
    "    \n",
    "    deduplicated_images.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return [image_file for _, image_file in deduplicated_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5wy0U1-2gcv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_img_colorbar(img):\n",
    "  # display the points\n",
    "  fig, ax = plt.subplots(figsize=(15, 10), nrows=2, ncols=2)\n",
    "  im_ax = plt.imshow(img, cmap='gray')\n",
    "  # create an axes on the right side of ax. The width of cax will be 5%\n",
    "  # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "  divider = make_axes_locatable(ax)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "  plt.colorbar(im_ax, cax=cax)\n",
    "  plt.show()\n",
    "\n",
    "def plot_imgs(imN, imA, imL, imS):\n",
    "    # display the points\n",
    "    fig, ax = plt.subplots(figsize=(15, 10), nrows=2, ncols=2)\n",
    "    ax[0][0].imshow(imN, cmap='gray')\n",
    "    ax[0][0].set_title(\"Normal (N)\")\n",
    "\n",
    "    ax[0][1].imshow(imA, cmap='gray')\n",
    "    ax[0][1].set_title(\"Adenocarcinoma (A)\")\n",
    "\n",
    "    ax[1][0].imshow(imL, cmap='gray')\n",
    "    ax[1][0].set_title(\"Large cell carcinoma (L)\")\n",
    "\n",
    "    ax[1][1].imshow(imS, cmap='gray')\n",
    "    ax[1][1].set_title(\"Squamous cell carcinoma (S)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0pDQuHk2sCp"
   },
   "outputs": [],
   "source": [
    "def generate_edges(img):\n",
    "    # extract the features from the image\n",
    "\n",
    "    # convert to grayscale\n",
    "    if np.max(img)>1:\n",
    "        img = img.astype(np.float32)/255.0\n",
    "    im_gray = np.mean(img, axis=2)\n",
    "\n",
    "    # compute edges of the image\n",
    "    sobelx = cv.Sobel(im_gray, cv.CV_32F, 1, 0, ksize=21) # Find x and y gradients\n",
    "    sobely = cv.Sobel(im_gray, cv.CV_32F, 0, 1, ksize=21)\n",
    "    magnitude = np.sqrt(sobelx**2.0 + sobely**2.0)\n",
    "    magnitude = magnitude / np.max(magnitude) # normalize\n",
    "\n",
    "    # threshold the image and get the interesting points\n",
    "    im_threshold = cv.Canny(image=(magnitude * 255).astype(np.uint8), threshold1=0, threshold2=100) # Canny Edge\n",
    "    im_threshold = im_threshold / np.max(im_threshold) # normalize\n",
    "\n",
    "    return magnitude, im_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hedcIOL12w-P"
   },
   "outputs": [],
   "source": [
    "edgesN, canny_edgesN = generate_edges(im_N)\n",
    "edgesA, canny_edgesA = generate_edges(im_A)\n",
    "edgesL, canny_edgesL = generate_edges(im_L)\n",
    "edgesS, canny_edgesS = generate_edges(im_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "318dHFb720sP"
   },
   "outputs": [],
   "source": [
    "plot_imgs(im_N, im_A, im_L, im_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQzXhRMq3WsH"
   },
   "outputs": [],
   "source": [
    "plot_imgs(edgesN, edgesA, edgesL, edgesS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCcIzUlO24YK"
   },
   "outputs": [],
   "source": [
    "plot_imgs(canny_edgesN, canny_edgesA, canny_edgesL, canny_edgesS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-arji1ltqxxl"
   },
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eyyt6CLW3wow"
   },
   "outputs": [],
   "source": [
    "class_mappings = {\n",
    "    0: \"normal\",\n",
    "    1: \"adenocarcinoma\",\n",
    "    2: \"large.cell.carcinoma\",\n",
    "    3: \"squamous.cell.carcinoma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4DjLEbOqz6W"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_path = \"/content/drive/MyDrive/W281/Final Project/Data_Cropped_and_Resized/train\"\n",
    "\n",
    "train_imgs, train_sobel_edges, train_labels = extract_features(train_path, detect_edges_sobel, class_mappings)\n",
    "_, train_hounsfield_edges, _ = extract_features(train_path, apply_hounsfield_units, class_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qsl5sxHwq8h1"
   },
   "outputs": [],
   "source": [
    "valid_path = \"/content/drive/MyDrive/W281/Final Project/Data_Cropped_and_Resized/valid\"\n",
    "\n",
    "valid_imgs, valid_sobel_edges, valid_labels = extract_features(valid_path, detect_edges_sobel, class_mappings)\n",
    "_, valid_hounsfield_edges, _ = extract_features(valid_path, apply_hounsfield_units, class_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WobpPdkrAZb"
   },
   "outputs": [],
   "source": [
    "plot_features(train_imgs, train_sobel_edges, train_labels, 0, 'Sobel Edge', class_mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnGSCPLSrHG8"
   },
   "outputs": [],
   "source": [
    "plot_features(train_imgs, train_hounsfield_edges, train_labels, 0, \"Hounsfield Unit\", class_mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJr2Q-g-3sPt"
   },
   "outputs": [],
   "source": [
    "train_path = \"/content/drive/MyDrive/W281/Final Project/Data/train\"\n",
    "val_path = \"/content/drive/MyDrive/W281/Final Project/Data/valid\"\n",
    "\n",
    "classN_train_path = train_path + \"/normal/\"\n",
    "classA_train_path = train_path + \"/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib/\"\n",
    "classL_train_path = train_path + \"/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa/\"\n",
    "classS_train_path = train_path + \"/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa/\"\n",
    "classN_valid_path = val_path + \"/normal/\"\n",
    "classA_valid_path = val_path + \"/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib/\"\n",
    "classL_valid_path = val_path + \"/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa/\"\n",
    "classS_valid_path = val_path + \"/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcFBgIU6rO6c"
   },
   "outputs": [],
   "source": [
    "mean_sizes = []\n",
    "\n",
    "print(\"CLASS: NORMAL\")\n",
    "mean_sizes.append(get_average_image_size(classN_train_path)[0])\n",
    "\n",
    "print(\"\\nCLASS: A\")\n",
    "mean_sizes.append(get_average_image_size(classA_train_path)[0])\n",
    "\n",
    "print(\"\\nCLASS: L\")\n",
    "mean_sizes.append(get_average_image_size(classL_train_path)[0])\n",
    "\n",
    "print(\"\\nCLASS: S\")\n",
    "mean_sizes.append(get_average_image_size(classS_train_path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XyKSpfHxeDh"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"CLASS: NORMAL\")\n",
    "mean_sizes.append(get_average_image_size(classN_valid_path)[0])\n",
    "\n",
    "print(\"\\nCLASS: A\")\n",
    "mean_sizes.append(get_average_image_size(classA_valid_path)[0])\n",
    "\n",
    "print(\"\\nCLASS: L\")\n",
    "mean_sizes.append(get_average_image_size(classL_valid_path)[0])\n",
    "\n",
    "print(\"\\nCLASS: S\")\n",
    "mean_sizes.append(get_average_image_size(classS_valid_path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7m_mIzmryMcI"
   },
   "outputs": [],
   "source": [
    "mean_sizes = np.array(mean_sizes)\n",
    "out_img_size = (int(np.round(mean_sizes[:, 0].mean())), int(np.round(mean_sizes[:, 1].mean())))\n",
    "\n",
    "print(f\"Mean of all images: {out_img_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B70I9TrSyOo5"
   },
   "outputs": [],
   "source": [
    "out_img_dir = \"/content/drive/MyDrive/W281/Final Project/Data_Cropped_and_Resized\"\n",
    "output_img_size = (256, 256)\n",
    "\n",
    "crop_and_resize_images(train_path, output_img_size, out_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q27-yZNVyTHy"
   },
   "outputs": [],
   "source": [
    "crop_and_resize_images(val_path, output_img_size, out_img_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sv9luXfyVUL"
   },
   "outputs": [],
   "source": [
    "img_name = \"/content/drive/MyDrive/W281/Final Project/Data/train/normal/n8.jpg\"\n",
    "img = plt.imread(img_name)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2jAyzyayYpU"
   },
   "outputs": [],
   "source": [
    "img_name = \"/content/drive/MyDrive/W281/Final Project/Data_Resized/train/normal/n8.jpg\"\n",
    "img = plt.imread(img_name)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xL1M9Gloyc84"
   },
   "outputs": [],
   "source": [
    "def show_slice_window(slice, level, window):\n",
    "   \"\"\"\n",
    "   Function to display an image slice\n",
    "   Input is a numpy 2D array\n",
    "   \"\"\"\n",
    "   max = level + window/2\n",
    "   min = level - window/2\n",
    "   slice = slice.clip(min,max)\n",
    "\n",
    "   fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "   ax[0].imshow(slice, cmap=\"gray\")\n",
    "\n",
    "   retval, thresh_gray = cv.threshold(slice,\n",
    "                                      thresh=50,\n",
    "                                      maxval=255,\n",
    "                                      type=cv.THRESH_BINARY)\n",
    "   ax[1].imshow(thresh_gray,\n",
    "                cmap='gray',\n",
    "                vmin=0,\n",
    "                vmax=255)\n",
    "\n",
    "   return thresh_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdDiK19YzBim"
   },
   "outputs": [],
   "source": [
    "img_N = cv.imread(\"/content/drive/MyDrive/W281/FinalProject/Data_Resized/train/normal/n9.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "img_N = cv.equalizeHist(img_N)\n",
    "\n",
    "# Calculate the histogram\n",
    "hist, bins = np.histogram(img_N.flatten(), 256, [0, 256])\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(bins[:-1], hist, width=1, color='gray')\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18BxggrTzDrh"
   },
   "outputs": [],
   "source": [
    "  def get_PCA(X_list, n_components=2):\n",
    "  pca_list = []\n",
    "  xpca_list = []\n",
    "  for X in X_list:\n",
    "    pca = PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True).fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "    pca_list.append(pca)\n",
    "    xpca_list.append(X_pca)\n",
    "  return pca_list, xpca_list\n",
    "\n",
    "def plot_PCA(X_list, labels, n_components=2):\n",
    "  pca_list, xpca_list = get_PCA(X_list, n_components=n_components)\n",
    "\n",
    "  plt.figure(figsize=(15,5))\n",
    "  colors = ['b-', 'm-']\n",
    "  for i in range(len(X_list)):\n",
    "    plt.plot(np.cumsum(pca_list[i].explained_variance_ratio_), colors[i], label=labels[i])\n",
    "  plt.xticks(np.arange(n_components)+1)\n",
    "  plt.yticks(np.linspace(0, 1, 8))\n",
    "  plt.grid(True)\n",
    "  plt.xlabel('Number of components')\n",
    "  plt.ylabel('Explained Variances')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def get_tsne(X_list, n_components=2):\n",
    "  xtsne_list = []\n",
    "  for X in X_list:\n",
    "    tsne = TSNE(n_components=n_components, random_state=0)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    xtsne_list.append(X_tsne)\n",
    "  return xtsne_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_C9PAgDd0lzd"
   },
   "outputs": [],
   "source": [
    "labels = ['sobel edges', 'houndsfield edges']\n",
    "\n",
    "training_features = [[img.flatten() for img in train_sobel_edges],\n",
    "            [img.flatten() for img in train_hounsfield_edges]]\n",
    "\n",
    "plot_PCA(training_features, labels, n_components=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6deAycU112kH"
   },
   "source": [
    "LDA with Sobel Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ipBJgEz0t4s"
   },
   "outputs": [],
   "source": [
    "X_sobel_pca, X_hounsfield_pca = get_PCA(training_features, n_components=48)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QgFCVJk07Ht"
   },
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_sobel_pca, train_labels)\n",
    "\n",
    "X_lda = lda.transform(X_sobel_pca)\n",
    "\n",
    "coef_lda = lda.coef_[0]\n",
    "intercept_lda = lda.intercept_[0]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for label in np.unique(train_labels):\n",
    "    plt.scatter(X_lda[train_labels == label, 0], X_lda[train_labels == label, 1], label=label)\n",
    "\n",
    "line_x = np.array([X_lda[:, 0].min() - 1, X_lda[:, 0].max() + 1])\n",
    "line_y = -(line_x * coef_lda[0] + intercept_lda) / coef_lda[1]\n",
    "\n",
    "plt.plot(line_x, line_y, c='black', linewidth=2, label='Fitted Line')\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.title('Fitted Line from Linear Discriminant Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMlW4X5815b9"
   },
   "source": [
    "LDA with Hounsfield Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DZMF_cZ1KFM"
   },
   "outputs": [],
   "source": [
    "lda.fit(X_hounsfield_pca, train_labels)\n",
    "\n",
    "X_lda = lda.transform(X_hounsfield_pca)\n",
    "\n",
    "coef_lda = lda.coef_[0]\n",
    "intercept_lda = lda.intercept_[0]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for label in np.unique(train_labels):\n",
    "    plt.scatter(X_lda[train_labels == label, 0], X_lda[train_labels == label, 1], label=label)\n",
    "\n",
    "line_x = np.array([X_lda[:, 0].min() - 1, X_lda[:, 0].max() + 1])\n",
    "line_y = -(line_x * coef_lda[0] + intercept_lda) / coef_lda[1]\n",
    "\n",
    "plt.plot(line_x, line_y, c='black', linewidth=2, label='Fitted Line')\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.title('Fitted Line from Linear Discriminant Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZthmxdvhTnVFzoYugMg1u",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
