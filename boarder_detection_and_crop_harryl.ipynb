{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6f8cc6",
   "metadata": {},
   "source": [
    "# Boarder Detection and Cropping\n",
    "To crop the image **before** the resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb62c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a289be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gray.shape is (552, 800)\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "thresh_gray.shape (552, 800)\n",
      "x is 126\n",
      "y is 34\n",
      "w is 544\n",
      "h is 488\n",
      "crop.shape is (488, 544)\n"
     ]
    }
   ],
   "source": [
    "n_path = 'Data/train/normal/6 - Copy (3).png'\n",
    "a_path = 'Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib/000061.png'\n",
    "l_path = 'Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa/000002.png'\n",
    "s_path = 'Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa/000003.png'\n",
    "\n",
    "def detect_boarder(image_path):\n",
    "    # load image\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20,10))\n",
    "    gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "    kernel_size = 5\n",
    "    sigma = 1.0\n",
    "    kernel = cv2.getGaussianKernel(kernel_size, sigma)\n",
    "    kernel = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    # Apply the Gaussian filter\n",
    "    gray = cv2.filter2D(gray, -1, kernel)\n",
    "    \n",
    "    print('gray.shape is', gray.shape)\n",
    "    print(gray[50:60, 50:60])\n",
    "    ax[0,0].imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[0,0].title.set_text(image_path + ' - Origin')\n",
    "    # gray = cv2.resize(img, None, fx=0.25, fy=0.25) # resize since image is huge\n",
    "    # gray = cv2.cvtColor(rsz_img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "\n",
    "    # threshold to get just the signature\n",
    "    retval, thresh_gray = cv2.threshold(gray, thresh=50, maxval=255, type=cv2.THRESH_BINARY)\n",
    "    ax[0,1].imshow(thresh_gray, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[0,1].title.set_text(image_path + ' - Threshold')\n",
    "    print(thresh_gray[50:60, 40:50])\n",
    "    print('thresh_gray.shape', thresh_gray.shape)\n",
    "    # find where the signature is and make a cropped region\n",
    "    points = np.argwhere(thresh_gray!=0) # find where the black pixels are\n",
    "    points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "    x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "#     x, y, w, h = x-10, y-10, w+20, h+20 # make the box a little bigger\n",
    "    print('x is',x)\n",
    "    print('y is',y)\n",
    "    print('w is', w)\n",
    "    print('h is', h)\n",
    "    crop = gray[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "    print('crop.shape is', crop.shape)\n",
    "    ax[1,0].imshow(crop, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[1,0].title.set_text(image_path + ' - Crop')\n",
    "    # get the thresholded crop\n",
    "    retval, thresh_crop = cv2.threshold(crop, thresh=50, maxval=255, type=cv2.THRESH_BINARY)\n",
    "    \n",
    "    ax[1,1].imshow(thresh_crop, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[1,1].title.set_text(image_path + ' - Cropped')\n",
    "    \n",
    "    # display\n",
    "    # cv2.imshow(\"Cropped and thresholded image\", thresh_crop) \n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "detect_boarder(n_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790efe35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mn_path\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE) \n\u001b[1;32m      2\u001b[0m sample_g \u001b[38;5;241m=\u001b[39m rgb2gray(sample)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = cv2.imread(n_path, cv2.IMREAD_GRAYSCALE) \n",
    "sample_g = rgb2gray(sample)\n",
    "print(sample)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].imshow(sample, cmap='gray', vmin=0, vmax=255)\n",
    "ax[0].title.set_text(image_path + ' - Threshold')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
