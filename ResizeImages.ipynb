{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "ueHweX_-2XD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6neQRN62HOn"
      },
      "source": [
        "## Resize/Crop images\n",
        "\n",
        "Reading an image in using matplotlib.pyplot.imread. Image data array has shape:\n",
        "\n",
        "- (M, N) for grayscale images.\n",
        "\n",
        "- (M, N, 3) for RGB images.\n",
        "\n",
        "- (M, N, 4) for RGBA images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI7Nyeki2HOi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_Oov9-12HOn"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/W281/Final Project/Data/train\"\n",
        "val_path = \"/content/drive/MyDrive/W281/Final Project/Data/valid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore mean image sizes"
      ],
      "metadata": {
        "id": "6VSH9aeDI67o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "0ipALaeB3J0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h4xJbSa2HOo"
      },
      "outputs": [],
      "source": [
        "mean_sizes = []\n",
        "\n",
        "print(\"CLASS: NORMAL\")\n",
        "mean_sizes.append(get_average_image_size(classN_train_path)[0])\n",
        "\n",
        "print(\"\\nCLASS: A\")\n",
        "mean_sizes.append(get_average_image_size(classA_train_path)[0])\n",
        "\n",
        "print(\"\\nCLASS: L\")\n",
        "mean_sizes.append(get_average_image_size(classL_train_path)[0])\n",
        "\n",
        "print(\"\\nCLASS: S\")\n",
        "mean_sizes.append(get_average_image_size(classS_train_path)[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Val"
      ],
      "metadata": {
        "id": "zYfbMh1J4uGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CLASS: NORMAL\")\n",
        "mean_sizes.append(get_average_image_size(classN_valid_path)[0])\n",
        "\n",
        "print(\"\\nCLASS: A\")\n",
        "mean_sizes.append(get_average_image_size(classA_valid_path)[0])\n",
        "\n",
        "print(\"\\nCLASS: L\")\n",
        "mean_sizes.append(get_average_image_size(classL_valid_path)[0])\n",
        "\n",
        "print(\"\\nCLASS: S\")\n",
        "mean_sizes.append(get_average_image_size(classS_valid_path)[0])\n"
      ],
      "metadata": {
        "id": "z3d5pzgS4vTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_sizes = np.array(mean_sizes)\n",
        "out_img_size = (int(np.round(mean_sizes[:, 0].mean())), int(np.round(mean_sizes[:, 1].mean())))\n",
        "\n",
        "print(f\"Mean of all images: {out_img_size}\")"
      ],
      "metadata": {
        "id": "4UgoXHMbM34l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crop and Resize images"
      ],
      "metadata": {
        "id": "tay3jQoAcRhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_mappings = {\n",
        "    0: \"normal\",\n",
        "    1: \"adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\",\n",
        "    2: \"large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\",\n",
        "    3: \"squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\"\n",
        "}\n",
        "\n",
        "def detect_border_and_crop(image):\n",
        "  kernel_size = 5\n",
        "  sigma = 1.0\n",
        "  kernel = cv2.getGaussianKernel(kernel_size, sigma)\n",
        "  kernel = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "  # Apply the Gaussian filter\n",
        "  gray = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "  # threshold to get just the signature\n",
        "  _, thresh_gray = cv2.threshold(gray, thresh=50, maxval=255, type=cv2.THRESH_BINARY)\n",
        "\n",
        "  # find where the signature is and make a cropped region\n",
        "  points = np.argwhere(thresh_gray!=0) # find where the black pixels are\n",
        "  points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
        "\n",
        "  try:\n",
        "    x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
        "    crop = gray[y:y+h, x:x+w] # create a cropped region of the gray image\n",
        "  except:\n",
        "    crop = gray\n",
        "\n",
        "  # get the thresholded crop\n",
        "  _, thresh_crop = cv2.threshold(crop, thresh=50, maxval=255, type=cv2.THRESH_BINARY)\n",
        "\n",
        "  return crop, thresh_crop\n",
        "\n",
        "def crop_and_resize_images(split_path, out_img_size, out_img_dir):\n",
        "  if not os.path.exists(out_img_dir):\n",
        "    os.makedirs(out_img_dir)\n",
        "  split = split_path.rpartition(\"/\")[2]\n",
        "  for label, class_name in class_mappings.items():\n",
        "    class_path = os.path.join(split_path, class_name)\n",
        "    for img_name in os.listdir(class_path):\n",
        "      if img_name.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "        print(img_name)\n",
        "        img = plt.imread(os.path.join(class_path, img_name))\n",
        "        cropped, _ = detect_border_and_crop(img)\n",
        "        resized_img = resize(img, out_img_size, anti_aliasing=True)\n",
        "        plt.imsave(out_img_dir+\"/\"+img_name, resized_img, cmap=\"gray\")\n"
      ],
      "metadata": {
        "id": "J7gKw-a0Ju8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_img_dir = \"/content/drive/MyDrive/W281/Final Project/Data_Cropped_and_Resized\"\n",
        "output_img_size = (256, 256)\n",
        "\n",
        "crop_and_resize_images(train_path, output_img_size, out_img_dir)"
      ],
      "metadata": {
        "id": "XsTWoNS2F-vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualize results"
      ],
      "metadata": {
        "id": "achDSDp8XW-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_name = \"/content/drive/MyDrive/W281/Final Project/Data/train/normal/n9.jpg\"\n",
        "img = plt.imread(img_name)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "wTNKO7Kcdo74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_name = \"/content/drive/MyDrive/W281/Final Project/Data_Resized/train/normal/n9.jpg\"\n",
        "img = plt.imread(img_name)\n",
        "plt.imshow(img, cmap=\"gray\")"
      ],
      "metadata": {
        "id": "v36rcQkJdo4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "Sv4aKRhue4Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcEod1fAb351"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}