{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LqMp70dd060c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import *\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS_4KGw9060d",
        "outputId": "e87b7b54-1141-40c1-be1d-c12fce0a1c1a"
      },
      "outputs": [],
      "source": [
        "data_dir = \"../Data_Cropped_and_Resized\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufktc1q_2a9F"
      },
      "source": [
        "### Transformer feature extraction\n",
        "https://huggingface.co/DunnBC22/vit-base-patch16-224-in21k_covid_19_ct_scans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading (…)rocessor_config.json: 100%|██████████| 228/228 [00:00<00:00, 171kB/s]\n",
            "/Users/ktnorton/anaconda3/envs/w281/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Downloading (…)lve/main/config.json: 100%|██████████| 745/745 [00:00<00:00, 1.84MB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 343M/343M [00:46<00:00, 7.35MB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extractor = AutoFeatureExtractor.from_pretrained(\"DunnBC22/vit-base-patch16-224-in21k_covid_19_ct_scans\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"DunnBC22/vit-base-patch16-224-in21k_covid_19_ct_scans\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transformer_feature_vector(image, model, extractor):\n",
        "  # Preprocess the image using the feature extractor\n",
        "  image = Image.fromarray(image).convert('RGB')\n",
        "  inputs = extractor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "  # Forward pass through the model's transformer (without the classification head)\n",
        "  with torch.no_grad():\n",
        "      feature_vector = model.vit(**inputs).last_hidden_state\n",
        "\n",
        "  # Optionally, convert to a NumPy array\n",
        "  feature_vector = feature_vector.numpy()\n",
        "\n",
        "  return feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = f\"{data_dir}/train\"\n",
        "\n",
        "_, train_transformer_feat, _ = extract_features(train_path, transformer_feature_vector, {\"model\": model, \"extractor\": extractor})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "w281",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
