{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LqMp70dd060c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import *\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS_4KGw9060d",
        "outputId": "e87b7b54-1141-40c1-be1d-c12fce0a1c1a"
      },
      "outputs": [],
      "source": [
        "data_dir = \"../Data_Cropped_and_Resized\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufktc1q_2a9F"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cUfY-irX2wQz"
      },
      "outputs": [],
      "source": [
        "train_path = f\"{data_dir}/train\"\n",
        "\n",
        "train_imgs, train_sobel_edges, train_labels = extract_features(train_path, detect_edges_sobel)\n",
        "_, train_hounsfield_edges, _ = extract_features(train_path, apply_hounsfield_units)\n",
        "_, train_threshold_edges, _ = extract_features(train_path, threshold_image)\n",
        "_, train_canny_edges, _ = extract_features(train_path, detect_canny_edges)\n",
        "_, train_soft_tissue, _ = extract_features(train_path, get_soft_tissue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_P2S5idG2yOT"
      },
      "outputs": [],
      "source": [
        "valid_path = f\"{data_dir}/valid\"\n",
        "\n",
        "valid_imgs, valid_sobel_edges, valid_labels = extract_features(valid_path, detect_edges_sobel)\n",
        "_, valid_hounsfield_edges, _ = extract_features(valid_path, apply_hounsfield_units)\n",
        "_, valid_threshold_edges, _ = extract_features(valid_path, threshold_image)\n",
        "_, valid_canny_edges, _ = extract_features(valid_path, detect_canny_edges)\n",
        "_, valid_soft_tissue, _ = extract_features(valid_path, get_soft_tissue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dimensionality reduction\n",
        "\n",
        "### individual edge features\n",
        "input_features = np.array([[img.flatten() for img in train_sobel_edges],\n",
        "                            [img.flatten() for img in train_hounsfield_edges],\n",
        "                            [img.flatten() for img in train_threshold_edges],\n",
        "                            [img.flatten() for img in train_canny_edges]])\n",
        "\n",
        "X_train_sobel_pca, X_train_hounsfield_pca, X_train_thresh_pca, X_train_canny_pca = get_PCA(input_features, n_components=2)[-1]\n",
        "X_train_sobel_tsne, X_train_hounsfield_tsne, X_train_thresh_tsne, X_train_canny_tsne = get_tsne(input_features, n_components=2)\n",
        "\n",
        "input_features = np.array([[img.flatten() for img in valid_sobel_edges],\n",
        "                            [img.flatten() for img in valid_hounsfield_edges],\n",
        "                            [img.flatten() for img in valid_threshold_edges],\n",
        "                            [img.flatten() for img in valid_canny_edges]])\n",
        "X_val_sobel_pca, X_val_hounsfield_pca, X_val_thresh_pca, X_val_canny_pca = get_PCA(input_features, n_components=2)[-1]\n",
        "X_val_sobel_tsne, X_val_hounsfield_tsne, X_val_thresh_tsne, X_val_canny_tsne = get_tsne(input_features, n_components=2)\n",
        "\n",
        "### combined features\n",
        "combined_train_features = np.array([[np.array([w, x, y, z]).flatten() for w, x, y, z in zip(train_sobel_edges, train_hounsfield_edges, train_threshold_edges, train_canny_edges)]])\n",
        "X_train_combined_pca = get_PCA(combined_train_features, n_components=2)[-1][0]\n",
        "X_train_combined_tsne = get_tsne(combined_train_features, n_components=2)[0]\n",
        "\n",
        "combined_val_features = np.array([[np.array([w, x, y, z]).flatten() for w, x, y, z in zip(valid_sobel_edges, valid_hounsfield_edges, valid_threshold_edges, valid_canny_edges)]])\n",
        "X_val_combined_pca = get_PCA(combined_val_features, n_components=2)[-1][0]\n",
        "X_val_combined_tsne = get_tsne(combined_val_features, n_components=2)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Parameter search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameter grid to search through\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "}\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "X_train = np.array([img.flatten() for img in train_soft_tissue])\n",
        "y_train = train_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameter search on the training data\n",
        "grid_search = GridSearchCV(dt_classifier, param_grid, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_val = np.array([img.flatten() for img in valid_soft_tissue])\n",
        "y_val = valid_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'random'}\n",
            "Best Model Accuracy: 0.5694444444444444\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "y_pred = best_model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Best Model Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "    'gamma': [0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "svm_model = SVC()\n",
        "\n",
        "X_train = np.array([img.flatten() for img in train_soft_tissue])\n",
        "y_train = train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_val = np.array([img.flatten() for img in valid_soft_tissue])\n",
        "y_val = valid_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
            "Best Model Accuracy: 0.8055555555555556\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "y_pred = best_model.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Best Model Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "w281",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
